{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Final Exam\n",
    "\n",
    "# Background on Python, iPython, Jupyter and Pandas\n",
    "\n",
    "[Python](https://www.python.org/) is a high-level general purpose programming language named after a [British comedy troup](https://www.youtube.com/user/MontyPython), created by a [Dutch programmer as a hobby project](http://en.wikipedia.org/wiki/Guido_van_Rossum) and maintained by an international group of friendly but opinionated python enthusiasts (`import this!`). Until June 2018, Guido van Rossum was the [Benevolent dictator for life](https://en.wikipedia.org/wiki/Benevolent_dictator_for_life) for the Python language, now decisions are made jointly by the Python Steering Council.\n",
    "\n",
    "Python is popular for data science because it's powerful, fast, plays well with others, runs everywhere, is easy to learn, highly readable, and open. Because it's general purpose it can be used for full-stack development. It's got a growing list of useful libraries for scientitic programming, data manipulation, data analysis. (Numpy, Scipy, Pandas, Scikit-Learn, Statsmodels, Matplotlib, Pybrain, etc.)\n",
    "\n",
    "[iPython](http://ipython.org/) is an enhanced, interactive python interpreter started as a grad school project by [Fernando Perez](http://fperez.org/). iPython (jupyter) notebooks allow you to run a multi-language (Python, R, Julia, Markdown, LaTex, etc) interpreter in your browser to create rich, portable, and sharable code documents.\n",
    "\n",
    "[Pandas](http://pandas.pydata.org/) is a libary created by [Wes McKinney](http://blog.wesmckinney.com/) that introduces the R-like dataframe object to Python and makes working with data in Python a lot easier. It's also a lot more efficient than the R dataframe and pretty much makes Python superior to R in every imaginable way (except for ggplot 2). \n",
    "\n",
    "\n",
    "# Final Exam\n",
    "\n",
    "This self-grading notebook serves as a final exam for the introductory course.\n",
    "If you have grasped the contents of the course, you should be able to complete\n",
    "this exam. \n",
    "\n",
    "It is essential that you answer each cell by assigning the solution to `QUESTION_#`\n",
    "where `#` is the question number.  \n",
    "\n",
    "We will start with a warm-up question that is already answered.\n",
    "\n",
    "## Getting started with Jupyter (iPython) Notebooks\n",
    "\n",
    "To start up a Jupyter notebook server, simply navigate to the directory where you want the notebooks to be saved and run the command\n",
    "\n",
    "```\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "A browser should open with a notebook navigator. Click the \"New\" button and select \"Python 3\".\n",
    "\n",
    "A beautiful blank notebook should open in a new tab\n",
    "\n",
    "Name the notebook by clicking on \"Untitled\" at the top of the page.\n",
    "\n",
    "Notebooks are squences of cells. Cells can be markdown, code, or raw text. Change the first cell to markdown and briefly describe what you are going to do in the notebook. \n",
    "\n",
    "## Getting started with Pandas\n",
    "\n",
    "We start by importing the libraries we're going to use any library in the notebook:E.G., `pandas` and `matplotlib`, `seaborn`, `Numpy`, `Statsmodels`\n",
    "\n",
    "\n",
    "\n",
    "## Question 0\n",
    "\n",
    "Create a 3-element 1-dimensional array containing the values [1,1,1]\n",
    "\n",
    "_Note_: This answer is not assessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Setup: The solution is used as a model\n",
    "\n",
    "QUESTION_0 = np.ones(3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Documentation with ``?``\n",
    "\n",
    "The Python language and its data science ecosystem is built with the user in mind, and one big part of that is access to documentation.\n",
    "Every Python object contains the reference to a string, known as a *doc string*, which in most cases will contain a concise summary of the object and how to use it.\n",
    "Python has a built-in ``help()`` function that can access this information and prints the results.\n",
    "For example, to see the documentation of the built-in ``len`` function, you can do the following:\n",
    "\n",
    "```ipython\n",
    "In [1]: help(len)\n",
    "Help on built-in function len in module builtins:\n",
    "\n",
    "len(...)\n",
    "    len(object) -> integer\n",
    "    \n",
    "    Return the number of items of a sequence or mapping.\n",
    "```\n",
    "\n",
    "Depending on your interpreter, this information may be displayed as inline text, or in some separate pop-up window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data into a Pandas DataFrame\n",
    "\n",
    "So far we've been working with many datasets and raw files during our class sessions. This functions below should be familiar for your to apply through out the exam\n",
    "\n",
    "Built-in Data Structures\n",
    "- strings \"\"\n",
    "- lists []\n",
    "- tuples ()\n",
    "- sets {}\n",
    "- dictionaries {'key':value}\n",
    "\n",
    "Additional Essential Data Structures\n",
    "\n",
    "- numpy arrays ([])\n",
    "- pandas Series\n",
    "- pandas DataFrame\n",
    "- tensorflow Tensors\n",
    "\n",
    "\n",
    "Today we'll primarily be working with the pandas DataFrame. The pandas DataFrame is a two-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes. It's basically a spreadsheet you can program and it's an incredibly useful Python object for data analysis. \n",
    "\n",
    "You can load data into a dataframe using Pandas' excellent `read_*` functions.\n",
    "\n",
    "We're going to try two of them: read_table & read_csv\n",
    "\n",
    "Pro tip: TAB COMPLETION!\n",
    "\n",
    "Pro tip: jupyter will pull the doc string for a command just by asking it a question.\n",
    "\n",
    "Pro tip: jupyter will give you the allowable arguments if you hit `shift + tab`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 1 (a) (i)\n",
    "\n",
    "Construct the correlation matrix\n",
    "\n",
    "$$\\left[\\begin{array}{ccc} 1 & 0.2 & 0.5 \\\\ 0.2 & 1 & 0.8 \\\\ 0.5 & 0.8 & 1 \\end{array}\\right]$$\n",
    "\n",
    "as a NumPy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (ii)\n",
    " Construct the correlation matrix\n",
    "\n",
    "$$\\left[\\begin{array}{ccc} 1 & 0.2 & 0.5 \\\\ 0.2 & 1 & 0.8 \\\\ 0.5 & 0.8 & 1 \\end{array}\\right]$$\n",
    "\n",
    "as a DataFrame with columns and index both equal to `['A', 'B', 'C']`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (iii) \n",
    "\n",
    "Load the momentum data in the CSV file `momentum.csv`, set the column `date` \n",
    "as the index, and ensure that `date` is a `DateTimeIndex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (iv) ##\n",
    "\n",
    "(a). Construct a DataFrame using the data loaded in the previous question 1 (iii)\n",
    "that contains the returns from momentum portfolio 5 in March and April 2016.\n",
    "\n",
    "(b). Load another data in the csv file `crimes.csv`and modify it into a dataframe using:\n",
    "\n",
    "HINT:Notice that that has some issues when it comes to column names. Your are required to fix the issues by editing, monipulating and probably deleting some clumns columns.: \n",
    "\n",
    "The expected solutions and cleaned data should implement: \n",
    "\n",
    "1. Remove white spaces\n",
    "\n",
    "2. Replacing spaces with underscore\n",
    "\n",
    "3. You should also remove the double occurence of \"_\" in DATE__OF_OCCURENCE. Do so below:\n",
    "\n",
    "4. Write code to drop column 'Location':\n",
    "\n",
    "5. Once cleaned, we would like you to describe the better global view of the dataset. By writing code to describe, generate a sum (of null). \n",
    "\n",
    "6. Select and subsett in pandas using: `''` or quote methods or .head methods on PRIMARY_DESCRIPTION column\n",
    "\n",
    "7. Obtain the value counts for PRIMARY_DESCRIPTION column\n",
    "\n",
    "8. selecting two columns: enter code to select two columns. It will look something like: dataframe[[column 1, column 2]] for \n",
    "'PRIMARY_DESCRIPTION', 'SECONDARY_DESCRIPTION']] and view only the few columns (first ten),then subset by row index also for the first ten (3:10)\n",
    "\n",
    "9. Data Sorting: Write code to sort values for theft column according to the date of occurance, in ascending and make use of inplace function argument. `HINT: You may realise that the something is not right especially the way the sort function is sorting the data. If your are convinced by this statement. Ensure that the date objects are handled well`. \n",
    "\n",
    "10. Finally apply `Functions to series` use `Group by` year and month to look at data on a month to month basis.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 \n",
    "\n",
    "(a). What is the standard deviation of the data:\n",
    "\n",
    "$$ 1, 3, 1, 2,9, 4, 5, 6, 10, 4 $$\n",
    "\n",
    "**Note** Use 1 degree of freedom in the denominator.\n",
    "\n",
    "\n",
    "(b). Importing all relevant libraries \n",
    "\n",
    "`import pandas as pd, import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import math\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import time\n",
    "import re\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import sklearn\n",
    "from tqdm import tqdm_notebook\n",
    "pd.options.mode.chained_assignment = None`. \n",
    "\n",
    "Following the same format of code below: \n",
    "\n",
    "`team_converter = pd.read_csv(\"source_files/team_converter.csv\",encoding=\"cp1252\")\n",
    "big_five_league_fixtures = pd.read_csv(\"source_files/big_five_league_fixtures.csv\")\n",
    "big_five_league_fixtures[\"date\"] = big_five_league_fixtures[\"date\"].apply(lambda x:datetime.datetime.strptime(x,\"%d/%m/%Y\").date())\n",
    "big_five_league_fixtures[\"home_points\"] = big_five_league_fixtures[\"result\"].map({\"H\":3,\"D\":1,\"A\":0})\n",
    "big_five_league_fixtures[\"away_points\"] = big_five_league_fixtures[\"result\"].map({\"A\":3,\"D\":1,\"H\":0})`\n",
    "\n",
    "`FIFA_league_season_teams_df = pd.read_csv(\"output_files/FIFA_league_season_teams_df.csv\")\n",
    "FIFA_team_season_players_df = pd.read_csv(\"output_files/FIFA_team_season_players_df.csv\")\n",
    "TM_team_managers_df = pd.read_csv(\"output_files/TM_team_managers_df.csv\")`\n",
    "\n",
    "import and load all files as specified in the code\n",
    "\n",
    "b). \n",
    "\n",
    "(i). Run the code and adjust appropriate file paths to import and convert the dataset into proper format. \n",
    "\n",
    "(ii). Join the team ids onto fixture data. HINT: Using the same conversion and format of this exmple : First line of code `FIFA_edition_dict = {\n",
    "    \"FIFA 2005\":[\"08/10/2004\",\"/fifa05_1/\"],.....}` to complete all the joins for all years. \n",
    "\n",
    "(iii). Join Manager tenure onto fixture data. \n",
    "\n",
    "(iv). Join expected points onto fixture data. \n",
    "\n",
    "(v). Create dataframe of each team's performance in each season\n",
    "\n",
    "(vi). Create dataframe of each manager tenure, with past and future performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 \n",
    "\n",
    "(a). Load the covid-19 dataset in the CSV file `COVID-19 Cases.csv`, set the column `date` as the index, and ensure that `date` is a `DateTimeIndex`. Print a view of first 10 lines of the dataset. Next we will isolate the data we want to focus our attention on by creating a new DataFrame from the source, and by applying a few filters against it. We want to isolate the records where all the following conditions are true. First the Daily Difference count is greater than zero. Next the Case Type should be Confirmed. Finally, the Country_Region should be only Italy: Check whether the results are sorted by cases & ascending order to  well and accordingly, write the command to accomplish it:\n",
    "\n",
    "(b). Now lets visually display the distribution of the values in the Difference column. We can pass an array of values into the default hist() plot (`plot the histogram using the Difference Column`):\n",
    "\n",
    "(c). Obtain descriptive and inferential statics on at least three columns & create a new DataFrame out of the three columns computed statistics on. \n",
    "\n",
    "(d). Obtain a boxplot of the selected number of columns of your choice in the dataset. Interprete the resulting chart (boxplot) to make meaning out of it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "(a). Write the function `QUESTION_20` that will take a single input `s`, which is a string\n",
    "and will return a Series that counts the number of times each letter in `s` appears in `s`\n",
    "_without_ regard to case. Do not include spaces.  Ensure the Series returned as its index sorted.\n",
    "\n",
    "**Hints**:\n",
    "\n",
    "* Have a look at `value_counts` for a pandas `Series`.\n",
    "* You can iterate across the letters of a string using\n",
    "\n",
    "```\n",
    "some_string = 'abcdefg'\n",
    "for letter in some_string:\n",
    "    do somethign with letter...\n",
    "```\n",
    "* `str.lower` can be used to get the lower case version of a string\n",
    "\n",
    "(b). Use binary ufuncs, to do some interesting aggregates that can be computed directly from the object.\n",
    "For example, if we'd like to *reduce* an array with a particular operation, we can use the ``reduce`` method of any ufunc.\n",
    "A reduce repeatedly applies a given operation to the elements of an array until only a single result remains.\n",
    "\n",
    "For example, calling ``reduce`` on the ``add`` ufunc returns the sum of all elements in the array: `For x = np.arange(1, 6)`\n",
    "\n",
    "(i). reduce `x`\n",
    "\n",
    "(ii). add `x`\n",
    "\n",
    "(iii). multiply `x`\n",
    "\n",
    "(iv). accumulate `x`\n",
    "\n",
    "(v). compute additiona and accumulation in one row `x`\n",
    "\n",
    "(vi). compute multiplication and accumulation in one row `x`\n",
    "\n",
    "(V). do an outer product of `x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GOOD LUCK & `Be Not afraid of going slowly, be afraid of standing still` Old Chineese proverb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
